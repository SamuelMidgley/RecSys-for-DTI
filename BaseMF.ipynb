{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2971fbb8",
   "metadata": {},
   "source": [
    "# Base Matrix Factorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1924478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tdc.multi_pred import DTI\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from rdkit import Chem\n",
    "\n",
    "from BaseMF.RecSys import RatingDataset, MatrixFactorization\n",
    "from BaseMF.ModelTrainer import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef5ef",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46da1610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "To log space...\n"
     ]
    }
   ],
   "source": [
    "# load in the Kd dataset\n",
    "# method also works with IC50 and Ki datasets\n",
    "data = DTI(name = 'BindingDB_Kd')\n",
    "data.convert_to_log(form = 'binding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec8f78",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0baa5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    # split data using tdc modules random split using default 0.7, 0.1, 0.2 split\n",
    "    split = data.get_split(seed = 42)\n",
    "    train = split['train']\n",
    "    test = split['test']\n",
    "\n",
    "    # enumerate drugs and targets for easy indexing\n",
    "    ID_to_Drug = dict(enumerate(list(dict.fromkeys(train['Drug']))))\n",
    "    ID_to_Target = dict(enumerate(list(dict.fromkeys(train['Target']))))\n",
    "    Drug_to_ID = dict((v,k) for k,v in ID_to_Drug.items())\n",
    "    Target_to_ID = dict((v,k) for k,v in ID_to_Target.items())\n",
    "    \n",
    "    return train, test, Drug_to_ID, Target_to_ID\n",
    "\n",
    "def data_loader(data, drug_dict, target_dict):\n",
    "    # allows data to be correctly passed in to PyTorch DataLoader\n",
    "    \n",
    "    # apply ID dictionary to both drugs and targets\n",
    "    data[\"Drug_DictID\"] = data[\"Drug\"].apply(lambda x:drug_dict.get(x))\n",
    "    data[\"Target_DictID\"] = data[\"Target\"].apply(lambda x:target_dict.get(x))\n",
    "\n",
    "    # convert data into expected data types\n",
    "    drug_ID = data[\"Drug_DictID\"].to_numpy()\n",
    "    target_ID = data[\"Target_DictID\"].to_numpy()\n",
    "    features = np.vstack((drug_ID, target_ID)).T\n",
    "    label = data['Y'].to_numpy()\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791bd05",
   "metadata": {},
   "source": [
    "## Pytorch Matrix Factorisation model\n",
    "Code for the base model including `MatrixFactorisation` class and the `train_model` function was obtained and optimised from a [Medium article](https://medium.com/@rinabuoy13/explicit-recommender-system-matrix-factorization-in-pytorch-f3779bb55d74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e8274",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9dc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  avg training loss:  28.744853009291685  avg test loss:  22.552714266095844\n",
      "epoch:  5  avg training loss:  9.411021880113362  avg test loss:  8.825925954182942\n",
      "epoch:  10  avg training loss:  6.962901553821043  avg test loss:  6.674741765430995\n",
      "epoch:  15  avg training loss:  5.761123054014529  avg test loss:  5.582966150556292\n",
      "epoch:  20  avg training loss:  4.952517388948326  avg test loss:  4.8439661979675295\n",
      "epoch:  25  avg training loss:  4.3223791799910085  avg test loss:  4.268992957614717\n",
      "epoch:  30  avg training loss:  3.8111890153806716  avg test loss:  3.805216727937971\n",
      "epoch:  35  avg training loss:  3.4047574977405737  avg test loss:  3.43629849865323\n",
      "epoch:  40  avg training loss:  3.0816787836330186  avg test loss:  3.1445257822672525\n",
      "epoch:  45  avg training loss:  2.8213899979174464  avg test loss:  2.912009306181045\n",
      "epoch:  50  avg training loss:  2.606839837598019  avg test loss:  2.7228774672462825\n",
      "epoch:  55  avg training loss:  2.4254908924871454  avg test loss:  2.5652278661727905\n",
      "epoch:  60  avg training loss:  2.269154124084066  avg test loss:  2.431146504765465\n",
      "epoch:  65  avg training loss:  2.131905045991387  avg test loss:  2.3151761599949428\n",
      "epoch:  70  avg training loss:  2.009956334620877  avg test loss:  2.213697015671503\n"
     ]
    }
   ],
   "source": [
    "bs = 100\n",
    "n_factors = 20\n",
    "num_epochs = 100\n",
    "\n",
    "train, test, drug_dict, target_dict = data_split(data)\n",
    "x_train, y_train = data_loader(train, drug_dict, target_dict)\n",
    "x_test, y_test = data_loader(test, drug_dict, target_dict)\n",
    "\n",
    "train_dataloader = DataLoader(RatingDataset(x_train, y_train), batch_size=bs, shuffle=True)\n",
    "test_dataloader = DataLoader(RatingDataset(x_test, y_test), batch_size=bs)\n",
    "\n",
    "model = MatrixFactorization(len(drug_dict), len(target_dict), n_factors)\n",
    "\n",
    "train_losses, test_losses, trained_model = train_model(train_dataloader, test_dataloader, model, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b29921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and test losses\n",
    "\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.plot(epochs, train_losses, label='train')\n",
    "plt.plot(epochs, test_losses, label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "plt.legend()\n",
    "#     plt.savefig(img_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a369cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test set\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "predictions = []\n",
    "for i, (test_batch, label_batch) in enumerate(test_dataloader):\n",
    "    count = 1 + i\n",
    "    with torch.no_grad():\n",
    "        prediction = model(test_batch[:, 0].to(dev), test_batch[:, 1].to(dev))\n",
    "        predictions.extend(list(prediction.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc import Evaluator\n",
    "mse_evaluator = Evaluator(name = 'MSE')\n",
    "mae_evaluator = Evaluator(name = 'MAE')\n",
    "\n",
    "mse_score = mse_evaluator(y_test, predictions)\n",
    "mae_score = mae_evaluator(y_test, predictions)\n",
    "\n",
    "print('MSE: ', mse_score)\n",
    "print('MAE: ', mae_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
